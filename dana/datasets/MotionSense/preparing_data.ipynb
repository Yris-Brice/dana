{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1081446, 12) (331419, 12)\n",
      "Original Training Data Mean/Std:\n",
      "          acc_x     acc_y     acc_z     rot_x     rot_y     rot_z\n",
      "mean  0.032411  0.830334 -0.086742  0.004127  0.016184  0.013612\n",
      "std   0.441784  0.622959  0.506685  1.321412  1.246579  0.822903\n",
      "Original Test Data Mean/Std:\n",
      "          acc_x     acc_y     acc_z     rot_x     rot_y     rot_z\n",
      "mean  0.057188  0.696609 -0.141355  0.009218  0.009352  0.009982\n",
      "std   0.468595  0.662019  0.556168  1.195210  1.158414  0.757516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages/pandas/core/frame.py:3494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Training Data Mean/Std:\n",
      "              acc_x         acc_y         acc_z         rot_x         rot_y  \\\n",
      "mean -5.777648e-15  2.215782e-13 -5.838397e-15 -7.838207e-17 -6.861326e-17   \n",
      "std   1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
      "\n",
      "             rot_z  \n",
      "mean -9.545500e-17  \n",
      "std   1.000000e+00  \n",
      "Standardized Test Data Mean/Std:\n",
      "          acc_x     acc_y     acc_z     rot_x     rot_y     rot_z\n",
      "mean  0.056085 -0.214661 -0.107784  0.003853 -0.005480 -0.004411\n",
      "std   1.060690  1.062701  1.097660  0.904495  0.929274  0.920542\n",
      "Original Data:\n",
      " (1081446, 9) (331419, 9)\n",
      "Standardized Training Data Mean/Std:\n",
      "              acc_x         acc_y         acc_z         rot_x         rot_y  \\\n",
      "mean -5.777648e-15  2.215782e-13 -5.838397e-15 -7.838207e-17 -6.861326e-17   \n",
      "std   1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
      "\n",
      "             rot_z  \n",
      "mean -9.545500e-17  \n",
      "std   1.000000e+00  \n",
      "Standardized Test Data Mean/Std:\n",
      "          acc_x     acc_y     acc_z     rot_x     rot_y     rot_z\n",
      "mean  0.056085 -0.214661 -0.107784  0.003853 -0.005480 -0.004411\n",
      "std   1.060690  1.062701  1.097660  0.904495  0.929274  0.920542\n",
      "Stride for each Activity:\n",
      " {'STN': 25, 'STU': 25, 'WAL': 50, 'JOG': 25, 'STD': 50, 'SIT': 50}\n",
      "STN\n",
      "(4127, 128, 6, 1) (4127, 128, 6, 1)\n",
      "(848, 128, 6, 1) (848, 128, 6, 1)\n",
      "STU\n",
      "(9052, 128, 6, 1) (4925, 128, 6, 1)\n",
      "(1913, 128, 6, 1) (1065, 128, 6, 1)\n",
      "WAL\n",
      "(14508, 128, 6, 1) (5456, 128, 6, 1)\n",
      "(3189, 128, 6, 1) (1276, 128, 6, 1)\n",
      "JOG\n",
      "(18559, 128, 6, 1) (4051, 128, 6, 1)\n",
      "(4350, 128, 6, 1) (1161, 128, 6, 1)\n",
      "STD\n",
      "(22997, 128, 6, 1) (4438, 128, 6, 1)\n",
      "(5960, 128, 6, 1) (1610, 128, 6, 1)\n",
      "SIT\n",
      "(27629, 128, 6, 1) (4632, 128, 6, 1)\n",
      "(8014, 128, 6, 1) (2054, 128, 6, 1)\n",
      "Shapes:\n",
      " (27629, 128, 6, 1) (27629, 3) (8014, 128, 6, 1) (8014, 3)\n",
      "Activities Samples (Train):\n",
      " 2.0    5456\n",
      "1.0    4925\n",
      "5.0    4632\n",
      "4.0    4438\n",
      "0.0    4127\n",
      "3.0    4051\n",
      "Name: 0, dtype: int64\n",
      "Activities Samples (Test):\n",
      " 5.0    2054\n",
      "4.0    1610\n",
      "2.0    1276\n",
      "3.0    1161\n",
      "1.0    1065\n",
      "0.0     848\n",
      "Name: 0, dtype: int64\n",
      "(27629, 128, 6, 1) (27629,) \n",
      " (8014, 128, 6, 1) (8014,)\n",
      "Activity Weights {'STN': 1.116, 'STU': 0.935, 'WAL': 0.844, 'JOG': 1.137, 'STD': 1.038, 'SIT': 0.994}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "dataset_name = \"MotionSense\"\n",
    "x_train = pd.read_csv(dataset_name+\"_x_train.csv\")\n",
    "y_train = pd.read_csv(dataset_name+\"_y_train.csv\")    \n",
    "x_test = pd.read_csv(dataset_name+\"_x_test.csv\")\n",
    "y_test = pd.read_csv(dataset_name+\"_y_test.csv\")\n",
    "\n",
    "x_train[\"acc_x\"] = x_train[\"userAcceleration.x\"]+x_train[\"gravity.x\"]\n",
    "x_train[\"acc_y\"] = x_train[\"userAcceleration.y\"]+x_train[\"gravity.y\"]\n",
    "x_train[\"acc_z\"] = x_train[\"userAcceleration.z\"]+x_train[\"gravity.z\"]\n",
    "x_train = x_train.drop(columns=[\"userAcceleration.x\",\"userAcceleration.y\",\"userAcceleration.z\", \"gravity.x\", \"gravity.y\", \"gravity.z\"])\n",
    "x_train.rename(columns={\"rotationRate.x\":\"rot_x\", \"rotationRate.y\":\"rot_y\", \"rotationRate.z\":\"rot_z\"}, inplace=True)\n",
    "x_train.rename(columns={\"attitude.roll\":\"roll\", \"attitude.pitch\":\"pitch\", \"attitude.yaw\":\"yaw\"}, inplace=True)\n",
    "\n",
    "\n",
    "x_test[\"acc_x\"] = x_test[\"userAcceleration.x\"]+x_test[\"gravity.x\"]\n",
    "x_test[\"acc_y\"] = x_test[\"userAcceleration.y\"]+x_test[\"gravity.y\"]\n",
    "x_test[\"acc_z\"] = x_test[\"userAcceleration.z\"]+x_test[\"gravity.z\"]\n",
    "x_test = x_test.drop(columns=[\"userAcceleration.x\",\"userAcceleration.y\",\"userAcceleration.z\", \"gravity.x\", \"gravity.y\", \"gravity.z\"])\n",
    "x_test.rename(columns={\"rotationRate.x\":\"rot_x\", \"rotationRate.y\":\"rot_y\", \"rotationRate.z\":\"rot_z\"}, inplace=True)\n",
    "x_test.rename(columns={\"attitude.roll\":\"roll\", \"attitude.pitch\":\"pitch\", \"attitude.yaw\":\"yaw\"}, inplace=True)\n",
    "\n",
    "y_train.rename(columns={\"act\":\"activity\", \"id\":\"userid\"}, inplace=True)\n",
    "y_test.rename(columns={\"act\":\"activity\", \"id\":\"userid\"}, inplace=True)\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "\n",
    "\n",
    "train_dataset = x_train\n",
    "train_dataset['activity'] = y_train['activity']\n",
    "train_dataset['userid'] = y_train['userid']\n",
    "train_dataset['trial'] = y_train['trial']\n",
    "\n",
    "\n",
    "test_dataset = x_test\n",
    "test_dataset['activity'] = y_test['activity']\n",
    "test_dataset['userid'] = y_test['userid']\n",
    "test_dataset['trial'] = y_test['trial']\n",
    "\n",
    "print(train_dataset.shape, test_dataset.shape)\n",
    "\n",
    "train_dataset = train_dataset[['acc_x', 'acc_y', 'acc_z', 'rot_x', 'rot_y', 'rot_z', \n",
    "                              'activity', 'userid', 'trial']]\n",
    "test_dataset = test_dataset[['acc_x', 'acc_y', 'acc_z', 'rot_x', 'rot_y', 'rot_z',\n",
    "                              'activity', 'userid','trial']]                              \n",
    "\n",
    "features = list(train_dataset.columns[:6])\n",
    "info = list(train_dataset.columns[6:])\n",
    "features, info                              \n",
    "\n",
    "\n",
    "\n",
    "print(\"Original Training Data Mean/Std:\\n\", train_dataset[features].describe().loc[['mean','std']])  \n",
    "print(\"Original Test Data Mean/Std:\\n\",test_dataset[features].describe().loc[['mean','std']])  \n",
    "\n",
    "data_train = train_dataset[features]\n",
    "data_means = data_train.mean(0)\n",
    "data_stds = data_train.std(0)\n",
    "train_dataset[features] = (data_train - data_means)/(data_stds)\n",
    "\n",
    "data_test = test_dataset[features]\n",
    "test_dataset[features] = (data_test - data_means)/(data_stds)\n",
    "\n",
    "print(\"Standardized Training Data Mean/Std:\\n\", train_dataset[features].describe().loc[['mean','std']])  \n",
    "print(\"Standardized Test Data Mean/Std:\\n\",test_dataset[features].describe().loc[['mean','std']])  \n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "class SensorWindowGenerator(TimeseriesGenerator):\n",
    "    def __init__(self, data, targets, info, length,\n",
    "                 sampling_rate=1,\n",
    "                 stride=1,\n",
    "                 start_index=0,\n",
    "                 end_index=None,\n",
    "                 shuffle=False,\n",
    "                 reverse=False,\n",
    "                 batch_size=128):\n",
    "        super().__init__(data, targets, length, sampling_rate, stride, start_index, end_index, shuffle,reverse,batch_size)\n",
    "        self.info = info\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.shuffle:\n",
    "            rows = np.random.randint(\n",
    "                self.start_index, self.end_index + 1, size=self.batch_size)\n",
    "        else:\n",
    "            i = self.start_index + self.batch_size * self.stride * index\n",
    "            rows = np.arange(i, min(i + self.batch_size *\n",
    "                                    self.stride, self.end_index + 1), self.stride)\n",
    "\n",
    "        samples = np.array([self.data[row - self.length:row:self.sampling_rate]\n",
    "                            for row in rows \n",
    "                            if np.all(self.info[row - self.length] == self.info[row]) ])\n",
    "        targets = np.array([self.targets[row] for row in rows if np.all(self.info[row - self.length] == self.info[row])])\n",
    "        \n",
    "        infos = np.array([self.targets[row] for row in rows if np.all(self.info[row - self.length] == self.info[row])])\n",
    "        \n",
    "        if self.reverse:\n",
    "            return samples[:, ::-1, ...], targets\n",
    "        return samples, targets\n",
    "\n",
    "def get_xyi_single(train_data, test_data, features, label, info):\n",
    "    x_train = train_data[features]\n",
    "    x_test  = test_data[features]\n",
    "    y_train = train_data[label]\n",
    "    y_test  = test_data[label]\n",
    "    i_train = train_data[info]\n",
    "    i_test  = test_data[info]\n",
    "    return x_train.values, y_train.values, x_test.values, y_test.values, i_train.values, i_test.values\n",
    "\n",
    "def get_generators(train_data, test_data, features, label, info, length, train_stride, test_stride, batch_size, sampling_rate):\n",
    "    x_train, y_train, x_test, y_test, i_train, i_test = get_xyi_single(train_data,test_data, features,label,info)\n",
    "    train_gen = SensorWindowGenerator(data = x_train,\n",
    "                                      targets = y_train,\n",
    "                                      info = i_train,\n",
    "                                      stride = train_stride, \n",
    "                                      length = length, \n",
    "                                      batch_size = batch_size,\n",
    "                                      sampling_rate=sampling_rate)\n",
    "    test_gen = SensorWindowGenerator(data = x_test,\n",
    "                                     targets = y_test,\n",
    "                                     info = i_train,\n",
    "                                     stride = test_stride, \n",
    "                                     length = length, \n",
    "                                     batch_size=batch_size,\n",
    "                                     sampling_rate=sampling_rate)\n",
    "    return train_gen, test_gen     \n",
    "################################################################################\n",
    "\n",
    "def get_data(train_dataset, test_dataset, sensors,acts,stride_size,w_size,\n",
    "             org_smpl_rate,re_size_smpl_rate,verbose=False):\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Original Data:\\n\", train_dataset.shape, test_dataset.shape)\n",
    "\n",
    "    features = list(train_dataset.columns[:6])    \n",
    "    info = list(train_dataset.columns[6:])\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Standardized Training Data Mean/Std:\\n\", train_dataset[features].describe().loc[['mean','std']])  \n",
    "        print(\"Standardized Test Data Mean/Std:\\n\",test_dataset[features].describe().loc[['mean','std']])  \n",
    "    if verbose:\n",
    "        print(\"Stride for each Activity:\\n\", dict(zip([act_lbls[x] for x in acts],stride_size)))\n",
    "\n",
    "    length = w_size ## Sliding Window length (Size)\n",
    "    sampling_rate = 1 ## Larger integers means lower frequency\n",
    "    batch_size = int(1e12)\n",
    "\n",
    "    X_train = np.zeros((0, int(w_size*(re_size_smpl_rate/org_smpl_rate)), len(features),1))\n",
    "    y_train = np.zeros((0, len(info)))\n",
    "    X_test =  np.zeros((0, int(w_size*(re_size_smpl_rate/org_smpl_rate)), len(features),1))\n",
    "    y_test =  np.zeros((0, len(info)))\n",
    "\n",
    "    for lbl in  sorted(train_dataset['activity'].unique()):\n",
    "        train_stride = stride_size[int(lbl)] ## Step Size of the Sliding Window for training\n",
    "        test_stride = train_stride ## Step Size of the Sliding Window for testing\n",
    "        \n",
    "        train_gen, test_gen = get_generators(train_dataset[train_dataset['activity']==lbl],\n",
    "                                            test_dataset[test_dataset['activity']==lbl],\n",
    "                                            features,\n",
    "                                            ['activity', 'userid','trial'],                                                                                      \n",
    "                                            ['userid','trial'],\n",
    "                                            length, train_stride, test_stride, batch_size, sampling_rate)\n",
    "                \n",
    "        x_train_gen, y_train_gen = train_gen[0]\n",
    "        x_test_gen, y_test_gen = test_gen[0]\n",
    "        \n",
    "        x_train_gen = np.expand_dims(x_train_gen,3)\n",
    "        x_test_gen = np.expand_dims(x_test_gen,3)\n",
    "        \n",
    "        X_train = np.append(X_train, x_train_gen, axis=0)\n",
    "        y_train = np.append(y_train, y_train_gen, axis=0)\n",
    "        X_test = np.append(X_test, x_test_gen, axis=0)\n",
    "        y_test = np.append(y_test, y_test_gen, axis=0)\n",
    "        if verbose:\n",
    "            print(act_lbls[int(lbl)])\n",
    "            print(X_train.shape, x_train_gen.shape)\n",
    "            print(X_test.shape, x_test_gen.shape)\n",
    "\n",
    "    nb_act_classes = len(np.unique(y_train[:,0]))\n",
    "\n",
    "    if verbose:        \n",
    "        print(\"Shapes:\\n\", X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "        print(\"Activities Samples (Train):\\n\", pd.DataFrame(y_train[:,0])[0].value_counts())\n",
    "        print(\"Activities Samples (Test):\\n\", pd.DataFrame(y_test[:,0])[0].value_counts())\n",
    "    ###################### ONLY ACT #################\n",
    "    return X_train, y_train[:,0], X_test, y_test[:,0]\n",
    "\n",
    "act_lbls = [\"STN\",\"STU\",\"WAL\",\"JOG\",\"STD\",\"SIT\"]\n",
    "\n",
    "w_time = 2.56\n",
    "\n",
    "org_smpl_rate = 50\n",
    "re_size_smpl_rate = 50\n",
    "stride_size = np.array([25,25,50,25,50,50])\n",
    "\n",
    "w_size = int(w_time*org_smpl_rate)\n",
    "ms_X_train, ms_Y_train, ms_X_test, ms_Y_test = get_data(train_dataset, test_dataset,\n",
    "                                                        sensors =\"ag\",\n",
    "                                            acts = [0,1,2,3,4,5],\n",
    "                                            stride_size = stride_size,\n",
    "                                            w_size = w_size, \n",
    "                                            org_smpl_rate = org_smpl_rate,\n",
    "                                            re_size_smpl_rate=re_size_smpl_rate,\n",
    "                                            verbose=True)\n",
    "print(ms_X_train.shape, ms_Y_train.shape, \"\\n\",\n",
    "      ms_X_test.shape, ms_Y_test.shape)\n",
    "\n",
    "nb_act_classes = len(np.unique(ms_Y_train))\n",
    "ms_act_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                range(nb_act_classes),\n",
    "                                                ms_Y_train).round(3)\n",
    "ms_act_weights_dict = dict(zip(range(len(ms_act_weights)),ms_act_weights))                                                \n",
    "print(\"Activity Weights\",dict(zip(act_lbls,ms_act_weights)))\n",
    "\n",
    "np.save(\"X_train.npy\", ms_X_train[:,:,:,0])\n",
    "np.save(\"X_test.npy\", ms_X_test[:,:,:,0])\n",
    "np.save(\"y_train.npy\", ms_Y_train)\n",
    "np.save(\"y_test.npy\", ms_Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
